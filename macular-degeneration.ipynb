{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Automatic eye diseases classification of optical coherence tomography (OCT) images using machine learningÂ model** <br>\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n \nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport random\nimport cv2\nimport copy\n\nimport torch\nimport torch.nn as nn\nfrom collections import Counter\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets\n\nimport torchvision.transforms as tt\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nimport matplotlib.gridspec as gridspec\n\nfrom torch.utils.data import random_split, DataLoader\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n%matplotlib inline \nimport os\nprint(os.listdir('../input'))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Data Loading and Structure\n\n","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/kermany2018/OCT2017 '\n\n# Data Parameters\ntrain = 'train'\nval = 'val'\ntest = 'test'\ndata_type = [train, val, test]\n\nprint(os.listdir(data_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#  Data Augmentation \n","metadata":{}},{"cell_type":"code","source":"# Model parameters\nimage_size = 128\npatch_size = 128 \n\n\ndata_transforms = {\n    train: tt.Compose([\n        tt.RandomResizedCrop(image_size),\n        tt.RandomHorizontalFlip(),\n        tt.RandomRotation(5),\n        tt.RandomGrayscale(),\n        tt.RandomAffine(translate=(0.05,0.05), degrees=0),\n        tt.ToTensor(),\n    ]),\n    val: tt.Compose([\n        tt.Resize(image_size),\n        tt.CenterCrop(image_size),\n        tt.RandomGrayscale(),\n        tt.ToTensor(),\n    ]),\n    test: tt.Compose([\n        tt.Resize(image_size),\n        tt.CenterCrop(image_size),\n        tt.RandomGrayscale(),\n        tt.ToTensor(),\n    ]),\n}\n\nimage_datasets = {\n    x: datasets.ImageFolder(os.path.join(data_dir, x), \n    transform=data_transforms[x])\n    for x in data_type\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in data_type}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each image is loaded as a tensor with a dimension of [3,128,128]. 3 indicates that each image is transformed as a color image with RGB channels, whereas 128 refers to its height and width respectively.","metadata":{}},{"cell_type":"code","source":"img, label = image_datasets[train][0]\nprint(img.shape, label)\nplt.imshow(img[1,:,:],'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Data Inspection and Data Imbalance \n\n","metadata":{}},{"cell_type":"code","source":"counter = []\nper = []\nfor i in range(len(image_datasets[train].classes)):\n    classes = image_datasets[train].targets\n    counter.append(Counter(classes)[i])\n\nfor i in range(len(image_datasets[train].classes)):\n    per.append(counter[i]/sum(counter))\n\ntrain_weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n    per, dataset_sizes[train])\n    \n%matplotlib inline \nfig = plt.figure(figsize= (16,9),constrained_layout=True)\ngs = fig.add_gridspec(1, 2)\n\nax = fig.add_subplot(gs[0, 0])\n\ncolors = ['blue', 'orange','green','red']\nax.bar(image_datasets[train].classes, counter, color = colors)\nax.set_title('Distribution of training set');\n\nax = fig.add_subplot(gs[0, 1])\n\nax.pie(per,labels = tuple(image_datasets[train].classes),autopct='%1.1f%%')\nax.set_title('Distribution of training set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we plot a series of image with different labels. As a semi-trained medical personal, the difference between the normal and abnormal is noticeable. However, the exact difference between those abnormal images cannot be expressed in a coherent manner.  It is required to detect exact yet subtle differences in medical images to make accurate diagnoses. For trained personnel, it takes a considerable amount time to master such skill set after seeing thousands of images. And doctors need a reasonable amount of time to make such diagnosis, and still we cannot guarantee such diagnosis is 100% accurate. Hence, it is desired to train a model so that it can correctly classify those images in a short time frame. \n","metadata":{}},{"cell_type":"code","source":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=4, ncols=3, figsize=(15,15))\n    for i in range(len(samples)):\n        image = cv2.cvtColor(imread(samples[i]), cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (256, 256)) \n        ax[i//3][i%3].imshow(image)\n        if i<3:\n            ax[i//3][i%3].set_title(\"Normal\", fontsize=20)\n        elif 3<= i < 6:\n            ax[i//3][i%3].set_title(\"DRUSEN\", fontsize=20)\n        elif 6<= i < 9:\n            ax[i//3][i%3].set_title(\"DME\", fontsize=20)\n        else:\n            ax[i//3][i%3].set_title(\"CNV\", fontsize=20)\n            \n        ax[i//3][i%3].axis('off')\n        \n## Plot training samples\nrand_samples = random.sample([os.path.join(data_dir+'/train/NORMAL', filename) \n                              for filename in os.listdir(data_dir+'/train/NORMAL')], 3) + \\\n    random.sample([os.path.join(data_dir+'/train/DRUSEN', filename) \n                   for filename in os.listdir(data_dir+'/train/DRUSEN')], 3) + \\\n    random.sample([os.path.join(data_dir+'/train/DME', filename) \n                   for filename in os.listdir(data_dir+'/train/DME')], 3) + \\\n    random.sample([os.path.join(data_dir+'/train/CNV', filename) \n                   for filename in os.listdir(data_dir+'/train/CNV')], 3)\n\nplot_samples(rand_samples)\nplt.suptitle('Training Set Samples', fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Preparing Train, Validation & Test Data\n\n ","metadata":{}},{"cell_type":"code","source":"train_size = round(len(image_datasets[train])*0.5) # \ntemp = len(image_datasets[train]) - train_size # 99%\n\ntrain_ds,temps = random_split(image_datasets[train], [train_size,temp])\n\n\nval_size = round(len(temps)*0.02) # 4%\ntemp = len(temps) - val_size # 99%\n\nval_ds,_ = random_split(temps, [val_size,temp])\n\nlen(train_ds),len(val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we have a total of 41,742 images in 128 batches, which means that we will divide 41,742 into 128 batches and each batch contains about 326 samples to train the model.","metadata":{}},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, patch_size, num_workers=8, pin_memory=True)\nval_dl = DataLoader(val_ds, patch_size, num_workers=8, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Setting Up GPU\n","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndevice = get_default_device()\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device) # yield will stop here, perform other steps, and the resumes to the next loop/batch\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#    Choosing Model Performance Metrics\n\n","metadata":{}},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds\n\ndef F1_score(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    \n    # precision, recall, and F1\n    cm  = confusion_matrix(labels, preds)\n    tn, fp, fn, tp = cm.ravel()\n    precision = tp/(tp+fp)\n    recall = tp/(tp+fn)\n    f1 = 2*((precision*recall)/(precision+recall))\n    \n    return precision,recall,f1,preds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#    Selectting Cost Function for the Task\n\n\n\n","metadata":{}},{"cell_type":"code","source":"class OCTresbase(nn.Module):\n        # this is for loading the batch of train image and outputting its loss, accuracy \n    # & predictions\n    def training_step(self, batch,weight):\n        images,labels = batch\n        out = self(images)                                      # generate predictions\n        loss = F.cross_entropy(out, labels,weight=weight)      # weighted compute loss\n\n        acc,preds = accuracy(out, labels)                       # calculate accuracy\n        \n        return {'train_loss': loss, 'train_acc':acc}\n    \n        # this is for computing the train average loss and acc for each epoch\n    def train_epoch_end(self, outputs):\n        batch_losses = [x['train_loss'] for x in outputs]       # get all the batches loss\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['train_acc'] for x in outputs]          # get all the batches acc\n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        \n        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n    \n    # this is for loading the batch of val/test image and outputting its loss, accuracy, \n    # predictions & labels\n    def validation_step(self, batch):\n        images,labels = batch\n        out = self(images)                                      # generate predictions\n        loss = F.cross_entropy(out, labels)                     # compute loss\n        acc,preds = accuracy(out, labels)                       # calculate acc & get preds\n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}\n    # detach extracts only the needed number, or other numbers will crowd memory\n    \n    # this is for computing the validation average loss and acc for each epoch\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]         # get all the batches loss\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['val_acc'] for x in outputs]            # get all the batches acc\n        \n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n    # this is for printing out the results after each epoch\n    def epoch_end(self, epoch, train_result, val_result):\n        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.\n              format(epoch+1, train_result['train_loss'], train_result['train_acc'],\n                     val_result['val_loss'], val_result['val_acc']))\n    \n    # this is for using on the test set, it outputs the average loss and acc, \n    # and outputs the predictions\n    def test_prediction(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}      \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#  8.  Model Selection: ResNET\n","metadata":{}},{"cell_type":"code","source":"resnet18 = models.resnet18(pretrained=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Transfer Learining\n","metadata":{}},{"cell_type":"code","source":"class OCTres(OCTresbase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet18(pretrained=True)\n        # Freeze training for all layers before classifier\n        for param in self.network.fc.parameters():\n            param.require_grad = False  \n        num_features = self.network.fc.in_features # get number of in features of last layer\n        self.network.fc = nn.Linear(num_features, 4) # replace model classifier\n    \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To properly evaluate the model, we develop some functions to achieve such goal.\n\n*   **evaluate**: calls the validation functions defined in the base model class above and return the output. Validation functions compute the validation average loss and accuracy for each epoch and determind the proper hyperparameters.  \n*   **get_lr**: Instead of using a fixed learning rate, we also construct a learning rate scheduler, which calculates the learning rate at batch index. This will change the learning rate after every batch of training. The adaptive apporach of learning rate ensures a faster training. \n*   **fit**: the fit function determines the best hyperparameters for the model and then save such model as the optimal model for our task on hand. \n*  **model.eval()**: informs the network that nothing new is to be learned and the model is used for testing only. \n* **model.train()**  sets the modules in the network in training mode which means that the model knows it has to learn the layers as opposed to the **model.eval()**\n*   **torch.no_grad()**: impacts and deactivates autograd engine. It will reduce memory usage and speed up computations. ","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, lr, model, train_loader, val_loader,weight, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n# def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n\n    torch.cuda.empty_cache() # release all the GPU memory cache\n    history = {}\n    \n    \n    optimizer = opt_func(model.parameters(), lr)\n\n    best_loss = 1 # initialize best loss, which will be replaced with lower better loss\n    for epoch in range(epochs):\n        \n        # Training Phase \n        model.train() \n        train_outputs = []      \n        lrs = []\n        \n        for batch in train_loader:\n            outputs = model.training_step(batch,weight)\n#             outputs = model.training_step(batch)\n\n            loss = outputs['train_loss']                          # get the loss\n            train_outputs.append(outputs)\n            # get the train average loss and acc for each epoch\n            train_results = model.train_epoch_end(train_outputs)                        \n            loss.backward()                                       # compute gradients\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()                                      # update weights\n            optimizer.zero_grad()                                 # reset gradients\n        \n        \n        # Validation phase\n        val_results = evaluate(model, val_loader)\n        \n        # Save best loss\n        if val_results['val_loss'] < best_loss and epoch + 1 > 4:\n            best_loss = min(best_loss, val_results['val_loss'])\n            best_model_wts = copy.deepcopy(model.state_dict())\n            #torch.save(model.state_dict(), 'best_model.pt')\n        \n        # print results\n        model.epoch_end(epoch, train_results, val_results)\n        \n        # save results to dictionary\n        to_add = {'train_loss': train_results['train_loss'],\n                  'train_acc': train_results['train_acc'],\n                 'val_loss': val_results['val_loss'],\n                  'val_acc': val_results['val_acc'], 'lrs':lrs}\n        \n        # update performance dictionary\n        for key,val in to_add.items():\n            if key in history:\n                history[key].append(val)\n            else:\n                history[key] = [val]\n    \n    model.load_state_dict(best_model_wts)                         # load best model\n    \n    return history, optimizer, best_loss\n            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\n\nmodel = to_device(OCTres(), device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Model Training and Evaluating\n\n\n","metadata":{}},{"cell_type":"code","source":"epochs = 20\nlr = 0.0005\ngrad_clip = None\nweight_decay = 1e-4\nopt_func = torch.optim.Adam\n# weighted loss for data class imbalance\n\nweight = np.array(per)\nweight = torch.FloatTensor(1/weight).to(device)\n\n\n\nhistory, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl,weight,\n                                    grad_clip=grad_clip, \n                                    weight_decay=weight_decay, \n                                    opt_func=opt_func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best loss is:', best_loss)\n# Save Model\nbestmodel = {'model': OCTres(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(bestmodel, './OCTResnet.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is for loading the model from a previously saved one\n\ndef load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n\n    model.eval()\n    return model\n\nmodel = load_checkpoint('./OCTResnet.pth')\n# model = to_device(OCTres(), device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Accuracy and Loss Plots\n","metadata":{}},{"cell_type":"code","source":"# Plot Accuracy and Loss \nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs+1))\nax1.plot(epoch_list, history['train_acc'], label='Train Accuracy')\nax1.plot(epoch_list, history['val_acc'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history['train_loss'], label='Train Loss')\nax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, epochs+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#  Predicting on Test Set\n","metadata":{}},{"cell_type":"code","source":"counter = []\nper = []\n# image_datasets[train].classes\nfor i in range(len(image_datasets[test].classes)):\n    classes = image_datasets[test].targets\n    counter.append(Counter(classes)[i])\n\nfor i in range(len(image_datasets[test].classes)):\n    per.append(counter[i]/sum(counter))\n\n    \ntrain_weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n    per, dataset_sizes[train])\n    \n%matplotlib inline \nfig = plt.figure(figsize= (16,9),constrained_layout=True)\ngs = fig.add_gridspec(1, 2)\n\nax = fig.add_subplot(gs[0, 0])\n\ncolors = ['blue', 'orange','green','red']\nax.bar(image_datasets[val].classes, counter, color = colors)\nax.set_title('Distribution of test set');\n\nax = fig.add_subplot(gs[0, 1])\n\nax.pie(per,labels = tuple(image_datasets[test].classes),autopct='%1.1f%%')\nax.set_title('Distribution of test set')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [model.validation_step(batch) for batch in test_loader] \n    results = model.test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(image_datasets[test])\ntest_dl = DataLoader(image_datasets[test], patch_size, num_workers=8, pin_memory=True)\n\ntest_dl = DeviceDataLoader(test_dl, device)\npreds,labels = test_predict(model.to(device), test_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Confusion Matrix\n ","metadata":{}},{"cell_type":"code","source":"# # Plot confusion matrix\ncm  = confusion_matrix(labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\nplt.xticks(range(4), ['CNV', 'DME','DRUSEN','Normal'], fontsize=16)\nplt.yticks(range(4), ['CNV', 'DME','DRUSEN','Normal'], fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute Performance Metrics\nfp = cm.sum(axis=0) - np.diag(cm)  \nfn = cm.sum(axis=1) - np.diag(cm)\ntp = np.diag(cm)\ntn = cm.sum() - (fp + fn + tp)\n\naccuracy = (np.array(preds) == np.array(labels)).sum() / len(preds)\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\nf1 = 2*((precision*recall)/(precision+recall))\n\nrecall = recall.astype(float)\nprecision = precision.astype(float)\nf1 = f1.astype(float)\n\nprint(\"Accuracy of the model is %.2f\"% accuracy)\nprint('Recall of the model is {}'.format(recall))\nprint('precision of the model is {}'.format(precision))\nprint('F1 score of the model is {}'.format(f1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#   Predictions Presentation \n","metadata":{}},{"cell_type":"code","source":"idxs = torch.tensor(np.append(np.arange(start=0, stop=4, step=1), \n                              np.arange(start=300, stop=304, step=1)))\nidxs = torch.tensor(np.append(idxs, \n                              np.arange(start=600, stop=604, step=1)))\nidxs = torch.tensor(np.append(idxs, \n                              np.arange(start=900, stop=904, step=1)))\n\nfig, ax = plt.subplots(nrows=4, ncols=4, figsize=(12,12),constrained_layout=True)\n\nfor c,i in enumerate(idxs):\n    img_tensor, label = image_datasets[test][i]\n    ax[c//4][c%4].imshow(img_tensor[0,:,:], cmap='gray')\n    ax[c//4][c%4].set_title('Label: {}\\nPrediction: {}'\n                            .format(image_datasets[test].classes[label], \n                                    image_datasets[test].classes[preds[i]]),\n                            fontsize=12)\n    ax[c//4][c%4].axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}